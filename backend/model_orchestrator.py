# model_orchestrator.py
# Model Orchestrator - Gemini Only

import os
import time
import json
from typing import Dict, List, Any, Optional
from custom_llm import CustomLLMEngine
from pc_insurance_knowledge import PCPromptEngine
from document_generation_engine import DocumentGenerationEngine
from datetime import datetime

class PerformanceMonitor:
    def __init__(self):
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.total_response_time = 0
        self.model_usage = {"gemini": 0}
        
    def record_request(self, success: bool, response_time: float, model_used: str):
        self.total_requests += 1
        self.total_response_time += response_time
        self.model_usage[model_used] = self.model_usage.get(model_used, 0) + 1
        
        if success:
            self.successful_requests += 1
        else:
            self.failed_requests += 1
    
    def get_performance_report(self) -> Dict[str, Any]:
        avg_response_time = self.total_response_time / self.total_requests if self.total_requests > 0 else 0
        success_rate = self.successful_requests / self.total_requests if self.total_requests > 0 else 0
        
        return {
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "failed_requests": self.failed_requests,
            "success_rate": success_rate,
            "average_response_time": avg_response_time,
            "model_usage": self.model_usage
        }

class ModelOrchestrator:
    def __init__(self):
        """Initialize Model Orchestrator with Gemini only"""
        self.local_llm = CustomLLMEngine()
        self.pc_engine = PCPromptEngine()
        self.doc_engine = DocumentGenerationEngine()
        self.performance_monitor = PerformanceMonitor()
        
        # Configuration
        self.max_retries = 3
        print("âœ… Model Orchestrator initialized with Gemini only")

    def _generate_with_gemini(self, prompt: str, task_type: str) -> Dict[str, Any]:
        """Generate response using Gemini only"""
        retries = 0
        last_error = None
        
        while retries < self.max_retries:
            try:
                print(f"ğŸ¤– Using Gemini API (attempt {retries + 1})")
                start_time = time.time()
                
                response = self.local_llm.generate_response(prompt)
                end_time = time.time()
                response_time = end_time - start_time
                
                if response and "Error:" not in response:
                    # Record successful request
                    self.performance_monitor.record_request(True, response_time, "gemini")
                    
                    return {
                        "success": True,
                        "response": response,
                        "model_used": "gemini",
                        "response_time": response_time,
                        "accuracy": 0.9  # High accuracy for Gemini
                    }
                else:
                    # Record failed request
                    self.performance_monitor.record_request(False, response_time, "gemini")
                    last_error = response if response else "Empty response"
                    retries += 1
                    
            except Exception as e:
                last_error = str(e)
                retries += 1
                print(f"âš ï¸ Attempt {retries} failed: {e}")
        
        # All attempts failed
        return {
            "success": False,
            "response": f"Error: All generation attempts failed. Last error: {last_error}",
            "model_used": "none",
            "response_time": 0,
            "accuracy": 0.0
        }

    def process_document_analysis(self, document_text: str) -> Dict[str, Any]:
        """Process document analysis using Gemini"""
        try:
            print("ğŸ“Š Processing document analysis with Gemini...")
            
            # Generate specialized prompt
            prompt = self.pc_engine.generate_analysis_prompt(document_text)
            
            # Generate response
            result = self._generate_with_gemini(prompt, "document_analysis")
            
            if result['success']:
                return {
                    "success": True,
                    "analysis": result['response'],
                    "model_used": result['model_used'],
                    "response_time": result['response_time'],
                    "prompt_length": len(prompt)
                }
            else:
                return result
                
        except Exception as e:
            print(f"âŒ Error in document analysis: {e}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "none"
            }

    def process_technical_requirements(self, document_text: str) -> Dict[str, Any]:
        """Generate technical requirements using Gemini"""
        try:
            print("ğŸ“‹ Generating technical requirements with Gemini...")
            
            # Generate specialized prompt
            prompt = self.pc_engine.generate_technical_requirements_prompt(document_text)
            
            # Generate response
            result = self._generate_with_gemini(prompt, "technical_requirements")
            
            if result['success']:
                return {
                    "success": True,
                    "technical_requirements": result['response'],
                    "model_used": result['model_used'],
                    "response_time": result['response_time'],
                    "prompt_length": len(prompt)
                }
            else:
                return result
                
        except Exception as e:
            print(f"âŒ Error in technical requirements generation: {e}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "none"
            }

    def process_hld_generation(self, input_text: str, project_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Generate HLD using Document Generation Engine with Gemini"""
        try:
            print("ğŸ“„ Generating HLD with Gemini...")
            start_time = time.time()
            
            result = self.doc_engine.generate_hld(input_text, project_context)
            end_time = time.time()
            
            return {
                "success": True,
                "hld_content": result,
                "model_used": "gemini",
                "response_time": end_time - start_time,
                "quality_score": 0.9,
                "specificity_score": 0.85
            }
            
        except Exception as e:
            print(f"âŒ Error in HLD generation: {e}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "none"
            }

    def process_lld_generation(self, input_text: str, hld_content: str, project_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Generate LLD using Document Generation Engine with Gemini"""
        try:
            print("ğŸ“„ Generating LLD with Gemini...")
            start_time = time.time()
            
            result = self.doc_engine.generate_lld(input_text, hld_content, project_context)
            end_time = time.time()
            
            return {
                "success": True,
                "lld_content": result,
                "model_used": "gemini",
                "response_time": end_time - start_time,
                "quality_score": 0.9,
                "specificity_score": 0.85
            }
            
        except Exception as e:
            print(f"âŒ Error in LLD generation: {e}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "none"
            }

    def process_backlog_generation(self, input_text: str, project_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Generate Backlog using Document Generation Engine with Gemini"""
        try:
            print("ğŸ“„ Generating Backlog with Gemini...")
            start_time = time.time()
            
            result = self.doc_engine.generate_backlog(input_text, project_context)
            end_time = time.time()
            
            return {
                "success": True,
                "backlog_content": result,
                "model_used": "gemini",
                "response_time": end_time - start_time,
                "quality_score": 0.9,
                "specificity_score": 0.85
            }
            
        except Exception as e:
            print(f"âŒ Error in Backlog generation: {e}")
            return {
                "success": False,
                "error": str(e),
                "model_used": "none"
            }

    def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        return {
            "primary_llm": "gemini",
            "fallback_llm": "none",
            "gemini_available": self.local_llm.gemini_model_instance is not None,
            "api_key_configured": self.local_llm.gemini_api_key is not None,
            "performance_metrics": self.performance_monitor.get_performance_report(),
            "configuration": {
                "primary_llm": "gemini",
                "fallback_enabled": False,
                "max_retries": self.max_retries
            }
        }

    def test_system(self) -> Dict[str, Any]:
        """Test the entire system"""
        print("ğŸ§ª Testing Model Orchestrator System...")
        
        # Test LLM Engine
        llm_test = self.local_llm.test_model()
        
        # Test document analysis
        test_document = "This is a test document for system validation."
        analysis_test = self.process_document_analysis(test_document)
        
        # Test technical requirements
        requirements_test = self.process_technical_requirements(test_document)
        
        return {
            "llm_test": llm_test,
            "analysis_test": analysis_test,
            "requirements_test": requirements_test,
            "system_status": self.get_system_status()
        }

# Test the Gemini-only orchestrator
if __name__ == "__main__":
    print("ğŸ§ª Testing Gemini-Only Model Orchestrator...")
    
    orchestrator = ModelOrchestrator()
    
    # Test system
    test_result = orchestrator.test_system()
    
    print(f"\nâœ… System Test Results:")
    print(f"   LLM Test: {'âœ… Success' if test_result['llm_test']['success'] else 'âŒ Failed'}")
    print(f"   Analysis Test: {'âœ… Success' if test_result['analysis_test']['success'] else 'âŒ Failed'}")
    print(f"   Requirements Test: {'âœ… Success' if test_result['requirements_test']['success'] else 'âŒ Failed'}")
    
    # Show system status
    status = test_result['system_status']
    print(f"\nğŸ“Š System Status:")
    print(f"   Primary LLM: {status['primary_llm']}")
    print(f"   Fallback LLM: {status['fallback_llm']}")
    print(f"   Gemini Available: {status['gemini_available']}")
    print(f"   API Key Configured: {status['api_key_configured']}")
    
    # Show performance metrics
    metrics = status['performance_metrics']
    print(f"\nğŸ“ˆ Performance Metrics:")
    print(f"   Total Requests: {metrics['total_requests']}")
    print(f"   Success Rate: {metrics['success_rate']:.2%}")
    print(f"   Average Response Time: {metrics['average_response_time']:.2f}s")
    print(f"   Model Usage: {metrics['model_usage']}")
    
    print(f"\nâœ… Gemini-Only Model Orchestrator: COMPLETE")
    print(f"ğŸš€ Using Gemini as the primary and only LLM!")
